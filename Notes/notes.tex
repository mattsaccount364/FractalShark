\documentclass[12pt]{article}

% --- Encoding / fonts (fixes OT1 issues + improves monospace metrics) ---
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% --- Math ---
\usepackage{amsmath}
\usepackage{amssymb}

% --- Layout ---
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% --- Better line breaking / fewer overfull boxes ---
\usepackage{microtype}
\emergencystretch=2em % last-resort "be less picky" knob for line breaks

% --- Links and cross-refs ---
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage[nameinlink,noabbrev]{cleveref}

% --- Convenience for inline code that may need breaks ---
\newcommand{\code}[1]{\texttt{#1}}

\title{Notes on CUDA Mandelbrot Rendering Across Multiple Precisions}
\author{}
\date{}

\begin{document}
\maketitle


\section{Goal and overview}
\label{sec:goal}

The goal of these kernels is to \emph{render the Mandelbrot set} by computing an
\emph{escape-time} iteration count per pixel over a 2D image grid. Each CUDA
thread evaluates a single complex parameter \(c\) corresponding to one pixel,
iterates the Mandelbrot recurrence, and stores the iteration count into an
output buffer. Separate (or fused) stages can map iteration counts to colors,
apply palettes, and perform anti-aliasing.

Across kernels, the primary variation is the numeric representation used for
the orbit arithmetic: from IEEE-754 \code{float}/\code{double} up through
expansion types (float-float, double-double, quad-float, quad-double) and
HDR-normalized formats. The shared objective remains the same: compute the
escape-time for the Mandelbrot iteration as accurately and quickly as needed
for a desired zoom depth.


\section{The Mandelbrot set and escape-time rendering}
\label{sec:mandelbrot-intro}

The Mandelbrot set \(M\subset\mathbb{C}\) is defined as the set of complex
parameters \(c\) for which the orbit of
\begin{equation}
z_{n+1} = z_n^2 + c,\qquad z_0 = 0
\end{equation}
remains bounded. A common rendering method is \emph{escape-time}: iterate until
the orbit magnitude exceeds a bailout threshold, or until a maximum iteration
count is reached.

A standard bailout uses \(|z_n|^2 \ge 4\), since \(|z|>2\) implies divergence:
\begin{equation}
|z_n|^2 = \Re(z_n)^2 + \Im(z_n)^2 \ge 4 \quad\Rightarrow\quad \text{escaped.}
\end{equation}
For each pixel, the stored value is the smallest \(n\) (or a bounded proxy) at
which escape occurs, or the maximum iteration limit if escape never occurs.


\section{Pixel-to-parameter mapping}
\label{sec:mapping}

Each CUDA thread computes a pixel coordinate \((X,Y)\) and maps it to a complex
parameter \(c = x_0 + i y_0\). A typical kernel starts with:
\begin{verbatim}
int X = blockIdx.x * blockDim.x + threadIdx.x;
int Y = blockIdx.y * blockDim.y + threadIdx.y;
if (X >= width || Y >= height) return;
size_t idx = ConvertLocToIndex(X, height - Y - 1, width);
\end{verbatim}

\subsection{Thread-to-pixel mapping}
A 2D CUDA grid of 2D blocks covers the image. Each thread is responsible for one
pixel. The bounds check prevents out-of-range threads from writing.

\subsection{Y-axis convention}
The expression \code{height - Y - 1} flips \(Y\). This is common when the image
buffer uses a top-left origin but the complex-plane mapping assumes a
bottom-left origin (or vice versa).

\subsection{Affine map into the complex plane}
The parameter \(c\) is computed by an affine transform:
\begin{align}
x_0 &= cx + dx \cdot X, \\
y_0 &= cy + dy \cdot Y,
\end{align}
where \code{cx,cy} anchor the plane (e.g., the coordinate at pixel \((0,0)\)),
and \code{dx,dy} are per-pixel increments. Different kernels compute these
expressions in different numeric types; the intent is always the same: map each
pixel to its associated complex parameter \(c\).


\section{Mandelbrot recurrence in real arithmetic}
\label{sec:real-form}

Writing \(z = x + i y\) and \(c = x_0 + i y_0\), the iteration becomes:
\begin{align}
x_{n+1} &= x_n^2 - y_n^2 + x_0, \\
y_{n+1} &= 2 x_n y_n + y_0.
\end{align}
The escape test is:
\begin{equation}
x_n^2 + y_n^2 \ge 4 \quad\Rightarrow\quad \text{escaped.}
\end{equation}

Many kernels cache squares:
\[
zrsqr = x^2,\quad zisqr = y^2,
\]
so that \(x^2-y^2\) and \(x^2+y^2\) can be formed cheaply as \code{zrsqr - zisqr}
and \code{zrsqr + zisqr}. This is especially valuable when \(x\) and \(y\) are
represented by multi-component expansion types.


\section{Iteration chunking via \code{iteration\_precision}}
\label{sec:chunking}

Some kernels are templated on an integer \code{iteration\_precision}
(\(1,2,4,8,16\)) and unroll multiple Mandelbrot steps inside the loop:
\begin{itemize}
  \item Each loop iteration performs \code{iteration\_precision} updates.
  \item The counter \code{iter} increases by that amount.
  \item The maximum iteration \code{n\_iterations} is adjusted so \code{iter}
        does not exceed the requested limit.
\end{itemize}

This reduces loop overhead. The trade-off is that the escape predicate is
typically checked only once per chunk; therefore the reported escape iteration
can be larger than the true first-escape iteration by up to
\code{iteration\_precision - 1}. For strict escape iteration counts (e.g., for
continuous/smooth coloring based on the first bailout), use a chunk size of 1
or insert bailout checks within the unrolled body.


\section{Kernel family: numeric precision ladder for Mandelbrot rendering}
\label{sec:precision-ladder}

Each kernel variant renders the same Mandelbrot escape-time field; the only
difference is the numeric type used for mapping and orbit iteration. The
following sections describe how each type realizes the same recurrence and
escape test.

Throughout, \code{IterType} is the integer type used to store the escape-time
iteration count (e.g., \code{uint16\_t} or \code{uint32\_t}). An output color
buffer may appear in signatures (e.g., \code{AntialiasedColors OutputColorMatrix})
even when not written in the shown kernel body; the intent is to support a
coloring stage using the computed iteration counts.

\subsection{Kernel: \code{mandel\_1x\_float}}
\label{sec:mandel-1x-float}

\subsubsection{Numeric type}
This variant uses IEEE-754 single precision \code{float}. It provides the
highest throughput but limits usable zoom depth due to rounding error and loss
of significance in \(c\) and the orbit.

\subsubsection{FMA-based orbit update}
A typical implementation uses fused multiply-add intrinsics:
\begin{verbatim}
ytemp = __fmaf_rd(-y, y, x0);     // x0 - y^2
xtemp = __fmaf_rd(x, x, ytemp);   // x^2 - y^2 + x0
xtemp2 = 2.0f * x;
y = __fmaf_rd(xtemp2, y, y0);     // 2xy + y0
x = xtemp;
\end{verbatim}
This corresponds exactly to:
\begin{align}
x &\leftarrow x^2 - y^2 + x_0,\\
y &\leftarrow 2xy + y_0.
\end{align}
Using FMA reduces intermediate rounding and can improve performance. The
\code{\_\_fmaf\_rd} variant rounds downward; if IEEE round-to-nearest is desired,
use \code{\_\_fmaf\_rn} (or plain \code{fmaf}).

\subsubsection{Escape test}
The kernel tests \(x^2+y^2 < 4\) (often recomputing squares each loop in this
simplest variant).

\subsection{Kernel: \code{mandel\_1x\_double}}
\label{sec:mandel-1x-double}

\subsubsection{Numeric type}
This variant uses IEEE-754 \code{double} and therefore carries substantially
more mantissa precision than float. The Mandelbrot recurrence is identical, but
performance depends strongly on GPU FP64 throughput.

\subsubsection{Orbit update and escape test}
The update uses double-precision FMA intrinsics (e.g., \code{\_\_fma\_rd}) or
equivalent arithmetic to compute:
\[
x \leftarrow x^2 - y^2 + x_0,\qquad y \leftarrow 2xy + y_0,
\]
with the same bailout condition \(|z|^2 \ge 4\).

\subsection{Kernel: \code{mandel\_2x\_float}}
\label{sec:mandel-2x-float}

\subsubsection{Numeric type: float-float expansion}
This variant uses a float-float expansion type \code{dblflt} to represent a
value as:
\[
a \approx a_{\mathrm{hi}} + a_{\mathrm{lo}},
\]
where \code{head} (hi) carries the leading magnitude and \code{tail} (lo) is a
correction term. Arithmetic uses compensated routines such as
\code{add\_dblflt}, \code{sub\_dblflt}, \code{mul\_dblflt}, \code{sqr\_dblflt},
and often a specialized \code{mul\_dblflt2x(x,y)} to compute \(2xy\) with good
accuracy.

\subsubsection{Mapping and orbit iteration}
The affine mapping for \(c\) is performed in \code{dblflt}:
\[
x_0 = cx + dx \cdot X,\qquad y_0 = cy + dy \cdot Y,
\]
and the orbit update follows the same real-form recurrence using expansion
operations. Cached squares are typically maintained as \code{dblflt}:
\[
zrsqr = x^2,\quad zisqr = y^2.
\]

\subsubsection{Escape test}
Some implementations compare only the leading component (e.g., \code{head}) for
speed:
\[
zrsqr.\mathrm{head} + zisqr.\mathrm{head} < 4.
\]
This is fast but can misclassify points extremely near the boundary. A fully
robust bailout can incorporate both components (or a conservative bound).

\subsection{Kernel: \code{mandel\_2x\_double}}
\label{sec:mandel-2x-double}

\subsubsection{Numeric type: double-double expansion}
This variant uses a double-double type \code{dbldbl} representing:
\[
a \approx a_{\mathrm{hi}} + a_{\mathrm{lo}},
\]
with both components in double precision (often yielding \(\sim\)106 bits of
precision in favorable cases). This enables deeper zoom while retaining a
structure similar to the float-float kernel.

\subsubsection{Mapping, orbit update, and escape test}
The kernel computes the same affine mapping and iterates the same recurrence,
but with double-double arithmetic. The escape predicate may use the leading
component for speed, depending on the library layout and conventions in use.
If the implementation compares against a single component field (e.g., \code{.x}
or \code{.y}), verify that this field corresponds to the high part for that
library.

\subsection{Kernel: \code{mandel\_4x\_float}}
\label{sec:mandel-4x-float}

\subsubsection{Numeric type: quad-float (4-term expansion)}
This variant uses a four-float expansion type \code{GQF::gqf\_real}:
\[
a \approx a_0 + a_1 + a_2 + a_3,
\]
with decreasing-magnitude components. Pixel coordinates and constants are lifted
into this type (e.g., \code{make\_qf(X,0,0,0)}), then the affine mapping and orbit
update are performed in quad-float arithmetic.

\subsubsection{Orbit update and escape test}
The update implements:
\[
x \leftarrow x^2 - y^2 + x_0,\qquad y \leftarrow 2xy + y_0,
\]
using quad-float operations (including specialized square and power-of-two
multiply helpers). The escape test can be performed in the full quad-float type:
\[
zrsqr + zisqr \le 4.
\]
This yields a numerically faithful bailout for extreme zoom rendering.

\subsection{Kernel: \code{mandel\_4x\_double}}
\label{sec:mandel-4x-double}

\subsubsection{Numeric type: quad-double (4-term expansion)}
This variant uses a four-double expansion type \code{GQD::gqd\_real}:
\[
a \approx a_0 + a_1 + a_2 + a_3,\qquad a_k\in\mathbb{R}_{double}.
\]
It supports very deep zoom rendering with high numerical stability.

\subsubsection{Mapping, orbit update, and escape test}
The affine mapping and orbit update are evaluated in quad-double arithmetic. A
literal bailout constant (e.g., \code{4.0}) is promoted via overloads, so the
escape compare remains a full-precision comparison in the quad-double domain.

\subsection{Kernel: \code{mandel\_hdr\_float}}
\label{sec:mandel-hdr-float}

\subsubsection{Numeric type: HDR-normalized expansion}
This variant uses an HDR wrapper around an expansion type, e.g.:
\[
\code{HDRFloat<CudaDblflt<dblflt>>}.
\]
The intent is to combine (i) a wider mantissa via expansion arithmetic with
(ii) explicit normalization/reduction to maintain numeric conditioning and
dynamic range across many iterations.

\subsubsection{Reduction and stable comparisons}
The kernel frequently calls \code{Reduce()} / \code{HdrReduce()} on intermediate
values. These reductions are part of the numeric contract: norms and
comparisons are assumed to be applied to reduced/normalized values, enabling
specialized comparators without repeatedly materializing primitive scalars.

Instead of testing \(x^2+y^2 < 4\) in primitive form, the kernel maintains:
\[
zsq\_sum = zrsqr + zisqr
\]
and checks escape via a reduced comparator:
\begin{verbatim}
while (zsq_sum.compareToBothPositiveReduced(Four) < 0)
\end{verbatim}
This directly supports escape-time Mandelbrot rendering in HDR arithmetic while
keeping comparisons meaningful and stable.


\section{Perturbation Rendering of the Mandelbrot Set}
\label{sec:perturbation-concept}

This section explains \emph{perturbation} as a mathematical and algorithmic
technique for rendering the Mandelbrot set efficiently at deep zoom. The goal
is to compute accurate escape-time values for many nearby parameters \(c\)
while avoiding repeated high-precision evaluation of the full Mandelbrot
recurrence.

\subsection{Motivation: why perturbation is needed}

At large zoom depths, direct evaluation of
\[
z_{n+1} = z_n^2 + c,\qquad z_0=0,
\]
in floating-point arithmetic becomes inaccurate due to loss of significance in
\(c\) and accumulated rounding error. Using extended or arbitrary precision
solves the accuracy problem but is expensive when performed independently for
every pixel.

However, in a typical Mandelbrot image, nearby pixels correspond to parameters
\(c\) that differ only slightly. Their orbits therefore remain close for many
iterations. Perturbation exploits this coherence by computing one
high-precision \emph{reference orbit} and expressing nearby orbits as small
deviations from it.

\subsection{Reference orbit}

Choose a reference parameter \(c_\star\), usually the center of the current
view, and compute its orbit in sufficiently high precision:
\begin{equation}
z_{n+1}^\star = (z_n^\star)^2 + c_\star,\qquad z_0^\star = 0.
\end{equation}
The sequence \(\{z_n^\star\}\) is stored and reused for many pixels. This is the
only orbit that requires full high-precision evaluation.

\subsection{Delta formulation for nearby pixels}
\label{sec:perturb-delta-real}

For a pixel parameter \(c\) close to the reference parameter \(c_\star\), define
the parameter delta:
\begin{equation}
\Delta c \stackrel{\mathrm{def}}{=} c - c_\star,
\end{equation}
and express the orbit at iteration \(n\) as a perturbation of the reference
orbit:
\begin{equation}
z_n = z_n^\star + \Delta z_n,
\end{equation}
where \(\Delta z_n\) is the \emph{orbit delta}. Substituting into the Mandelbrot
recurrence,
\[
z_{n+1} = z_n^2 + c,
\]
gives:
\begin{align}
z_{n+1}
&= (z_n^\star + \Delta z_n)^2 + (c_\star + \Delta c) \\
&= (z_n^\star)^2 + 2z_n^\star \Delta z_n + (\Delta z_n)^2 + c_\star + \Delta c.
\end{align}
Subtracting the reference recurrence
\[
z_{n+1}^\star = (z_n^\star)^2 + c_\star
\]
yields the \emph{exact delta update}:
\begin{equation}
\Delta z_{n+1} = 2z_n^\star \Delta z_n + (\Delta z_n)^2 + \Delta c.
\label{eq:perturb-exact}
\end{equation}
No approximation has been made: perturbation preserves the exact Mandelbrot
dynamics as long as the reference orbit is computed accurately.

\subsubsection{Expansion into real and imaginary components}

To map \cref{eq:perturb-exact} directly to an implementation, write all
quantities in real and imaginary parts:
\begin{align*}
z_n^\star &= x_n^\star + i y_n^\star, \\
\Delta z_n &= \Delta x_n + i \Delta y_n, \\
\Delta c &= \Delta c_x + i \Delta c_y.
\end{align*}
First expand the quadratic term:
\begin{align}
(\Delta z_n)^2
&= (\Delta x_n + i \Delta y_n)^2 \\
&= (\Delta x_n^2 - \Delta y_n^2)
   + i(2 \Delta x_n \Delta y_n).
\end{align}
Next expand the linear term:
\begin{align}
2 z_n^\star \Delta z_n
&= 2(x_n^\star + i y_n^\star)(\Delta x_n + i \Delta y_n) \\
&= 2(x_n^\star \Delta x_n - y_n^\star \Delta y_n)
 + i\,2(x_n^\star \Delta y_n + y_n^\star \Delta x_n).
\end{align}
Combining terms gives the real and imaginary delta updates:
\begin{align}
\Delta x_{n+1}
&= 2(x_n^\star \Delta x_n - y_n^\star \Delta y_n)
   + (\Delta x_n^2 - \Delta y_n^2)
   + \Delta c_x, \label{eq:perturb-real} \\
\Delta y_{n+1}
&= 2(x_n^\star \Delta y_n + y_n^\star \Delta x_n)
   + 2\Delta x_n \Delta y_n
   + \Delta c_y. \label{eq:perturb-imag}
\end{align}

\subsubsection{Factored form used in implementations}

For numerical efficiency, \cref{eq:perturb-real,eq:perturb-imag} are typically
evaluated in a factored form. Grouping terms yields:
\begin{align}
\Delta x_{n+1}
&= \Delta x_n\,(2x_n^\star + \Delta x_n)
   - \Delta y_n\,(2y_n^\star + \Delta y_n)
   + \Delta c_x, \label{eq:perturb-real-factored} \\
\Delta y_{n+1}
&= \Delta x_n\,(2y_n^\star + \Delta y_n)
   + \Delta y_n\,(2x_n^\star + \Delta x_n)
   + \Delta c_y. \label{eq:perturb-imag-factored}
\end{align}
This corresponds exactly to the compact complex form:
\[
\Delta z_{n+1}
= \Delta z_n \bigl(2 z_n^\star + \Delta z_n\bigr) + \Delta c,
\]
and maps directly onto typical GPU code using temporaries such as:
\[
(2x_n^\star + \Delta x_n), \quad (2y_n^\star + \Delta y_n).
\]

\subsubsection{Reconstruction for escape testing}

Although perturbation evolves only the delta, escape-time rendering requires the
absolute orbit value:
\begin{equation}
z_n = z_n^\star + \Delta z_n
     = (x_n^\star + \Delta x_n) + i(y_n^\star + \Delta y_n).
\end{equation}
The standard Mandelbrot bailout condition is then applied:
\begin{equation}
|z_n|^2
= (x_n^\star + \Delta x_n)^2 + (y_n^\star + \Delta y_n)^2
\ge 4.
\end{equation}
This separation cleanly explains how perturbation math maps onto real-valued
implementation variables while preserving the exact Mandelbrot dynamics.


\subsection{Efficient perturbation update}

Equation~\eqref{eq:perturb-exact} can be rearranged into a form well suited for
implementation:
\begin{equation}
\Delta z_{n+1} = \Delta z_n \bigl(2z_n^\star + \Delta z_n\bigr) + \Delta c.
\label{eq:perturb-factored}
\end{equation}
This form requires only:
\begin{itemize}
\item one complex multiply,
\item one complex add,
\item access to the stored reference sample \(z_n^\star\).
\end{itemize}
Crucially, it avoids squaring large high-precision numbers for every pixel.
Instead, the expensive squaring is performed once for the reference orbit and
reused implicitly through \(z_n^\star\).

\subsection{Reconstructing the absolute orbit and escape test}

Perturbation evolves \(\Delta z_n\), but Mandelbrot rendering requires testing
escape of the absolute orbit. At each iteration, the current iterate is
reconstructed as:
\begin{equation}
z_n \approx z_n^\star + \Delta z_n.
\end{equation}
Escape-time rendering then applies the standard bailout condition:
\begin{equation}
|z_n|^2 = \Re(z_n)^2 + \Im(z_n)^2 \ge 4 \quad\Rightarrow\quad \text{escaped.}
\end{equation}
The iteration index \(n\) at which this condition is first satisfied (or the
maximum iteration count if it never is) determines the pixelâ€™s color.

\subsection{Numerical stability and recentering}

Perturbation is efficient only while \(\Delta z_n\) remains small relative to
\(z_n^\star\). If \(|\Delta z_n|\) grows comparable to or larger than
\(|z_n^\star|\), numerical cancellation and loss of significance can degrade
accuracy.

To maintain stability, practical implementations use \emph{recentering}. When
a stability criterion is violated, the current approximation is folded into a
new base:
\begin{equation}
z_n^\star \leftarrow z_n^\star + \Delta z_n,\qquad \Delta z_n \leftarrow 0,
\end{equation}
and perturbation continues relative to this updated reference state. This
preserves correctness while keeping deltas small.

\subsection{Why perturbation accelerates Mandelbrot rendering}

The efficiency gains come from two sources:
\begin{itemize}
\item \textbf{Reduced arithmetic cost.} Only one orbit is computed in full
high precision. All other pixels use cheaper delta updates.
\item \textbf{Spatial coherence.} Nearby pixels share the same reference orbit
for many iterations before diverging.
\end{itemize}
As a result, perturbation enables deep-zoom Mandelbrot rendering that would be
prohibitively slow if each pixel were evaluated independently in arbitrary
precision.

\subsection{Relation to other acceleration techniques}

Perturbation alone preserves the exact dynamics of the Mandelbrot map and
requires no linearization. It can be used by itself or combined with further
approximations (such as linear or bilinear approximation steps) to skip multiple
iterations at once. In all cases, perturbation provides the mathematical
foundation that makes efficient deep-zoom Mandelbrot rendering feasible.


\section{Reference Orbit Calculation}
\label{sec:ref-orbit-calc}

This section describes how \texttt{RefOrbitCalc} constructs (and optionally reuses) a high-precision
\emph{reference orbit} for perturbation rendering of the quadratic map
\begin{equation}
  z_{n+1} = z_n^2 + c,\qquad z,c\in\mathbb{C},
\end{equation}
with an implementation that supports single-threaded CPU, multi-threaded CPU, and GPU backends, plus
several storage/compression modes that trade memory footprint against recomputation.

\subsection{High-level pipeline and dispatch}
\label{subsec:ref-orbit-pipeline}

A reference orbit is stored in a \texttt{PerturbationResults<IterType,T,PExtras>} instance, where:
\begin{itemize}
  \item \texttt{IterType} is the iteration index type (\texttt{uint32\_t} or \texttt{uint64\_t}).
  \item \texttt{T} is the low-precision numeric type used for downstream perturbation math (e.g.\ \texttt{float},
        \texttt{double}, \texttt{HDRFloat<...>}).
  \item \texttt{PExtras} selects the storage format for per-iteration orbit data:
        uncompressed (\texttt{Disable}), a lightweight compressor (\texttt{SimpleCompression}),
        or additional diagnostic bookkeeping (e.g.\ \texttt{Bad}).
\end{itemize}

Orbit construction is initiated through \texttt{AddPerturbationReferencePoint()}, which:
\begin{enumerate}
  \item Picks an initial guess \((c_x,c_y)\) (center of the current view if unset).
  \item Chooses an algorithm (\texttt{ST}, \texttt{MT}, reuse-based hybrids, or \texttt{GPU}) based on
        \texttt{m\_PerturbationAlg} and zoom factor heuristics.
  \item Allocates a new \texttt{PerturbationResults} slot, initializes metadata and bounds, and runs the chosen
        orbit kernel until escape, periodicity detection, or the maximum iteration count is reached.
\end{enumerate}

To control memory pressure, \texttt{OptimizeMemory()} monitors process commit usage and opportunistically
drops cached orbits that are not of the currently demanded variant type when the working set exceeds
a configurable threshold.

\subsection{Single-threaded authoritative orbit}
\label{subsec:ref-orbit-st}

The single-threaded path (\texttt{AddPerturbationReferencePointST}) computes the authoritative orbit
directly using MPIR/GMP \texttt{mpf\_t} for the recurrence, while simultaneously emitting a low-precision
shadow copy \((\hat{x}_n,\hat{y}_n)\in T^2\) for downstream work (compression, bailout checks, periodicity tests).

\paragraph{State and initialization.}
Given a selected reference parameter \(c = c_x + i c_y\), the implementation:
\begin{itemize}
  \item Initializes \texttt{mpf\_t} temporaries for \(x,y,x^2\), and scratch products.
  \item Sets the initial iterate \((x_0,y_0) = (c_x,c_y)\) (this code uses the common convention \(z_0=c\)).
  \item Computes low-precision cast values \(\hat{c}_x,\hat{c}_y \in T\) either via \texttt{mpf\_get\_d} for
        native float/double, or via a mantissa/exponent extraction for extended formats.
\end{itemize}

\paragraph{Recurrence.}
Writing \(z_n = x_n + i y_n\), one iteration evaluates
\begin{align}
  x_{n+1} &= x_n^2 - y_n^2 + c_x, \\
  y_{n+1} &= 2 x_n y_n + c_y.
\end{align}
The implementation uses:
\begin{itemize}
  \item \texttt{mpf\_mul} and \texttt{mpf\_sub}/\texttt{mpf\_add} for the high-precision update.
  \item A low-precision snapshot \((\hat{x}_n,\hat{y}_n)\) acquired once per iteration for storage/compression,
        periodicity heuristics, and bailout checks.
\end{itemize}

\paragraph{Bailout.}
The bailout threshold is evaluated in low precision using
\begin{equation}
  \|\hat{z}_n + \hat{c}\|^2 = (\hat{x}_n + \hat{c}_x)^2 + (\hat{y}_n + \hat{c}_y)^2 > 256,
\end{equation}
which matches the code's use of \texttt{TwoFiftySix} and avoids a high-precision norm each step.

\subsection{Periodicity tracking via \texorpdfstring{$\partial z/\partial c$}{dz/dc}}
\label{subsec:ref-orbit-periodicity}

Several modes enable periodicity detection. The implementation tracks the complex derivative
\(\frac{\partial z_n}{\partial c}\) in low precision:
\begin{equation}
  d_{n+1} = 2 z_n d_n + 1,\qquad d_0 = 1,
\end{equation}
with \(d_n = d_{x,n} + i d_{y,n}\). Expanding into real and imaginary parts yields:
\begin{align}
  d_{x,n+1} &= 2(x_n d_{x,n} - y_n d_{y,n}) + 1, \\
  d_{y,n+1} &= 2(x_n d_{y,n} + y_n d_{x,n}).
\end{align}

The code applies a radius-based heuristic: let
\begin{equation}
  n_2 = \max(|\hat{x}_n|,|\hat{y}_n|),\qquad
  r_0 = \max(|d_{x,n}|,|d_{y,n}|),
\end{equation}
and define a detection threshold
\begin{equation}
  n_3 = 2\,R_{\max}\,r_0,
\end{equation}
where \(R_{\max}\) is the maximum perturbation radius stored in \texttt{results}. If \(n_2 < n_3\), the
orbit is marked as \emph{maybe periodic} and the reference loop terminates early (unless benchmarking
mode disables the break). Otherwise, \((d_{x,n},d_{y,n})\) is advanced using the update above.

\subsection{Compression and reuse datasets}
\label{subsec:ref-orbit-compression-reuse}

Two orthogonal storage decisions are made while iterating:
\begin{enumerate}
  \item \textbf{Orbit storage} for perturbation use (\texttt{PExtras}):
  \begin{itemize}
    \item \texttt{Disable}: store every \((\hat{x}_n,\hat{y}_n)\) uncompressed.
    \item \texttt{SimpleCompression}: store a compressed subset of iterations using an error exponent
          determined by \texttt{Fractal::CompressionError}.
    \item \texttt{Bad}: store orbit values plus underflow/diagnostic flags.
  \end{itemize}
  \item \textbf{Reuse storage} for intermediate-precision regeneration (\texttt{ReuseMode}):
  \begin{itemize}
    \item \texttt{SaveForReuse1/2}: store uncompressed \texttt{mpf\_t} reuse entries.
    \item \texttt{SaveForReuse3}: store an intermediate-compressed reuse stream.
    \item \texttt{SaveForReuse4}: store a maximally-compressed intermediate reuse stream.
  \end{itemize}
\end{enumerate}

The authoritative orbit and the reuse stream are logically decoupled: the first feeds perturbation
evaluation, while the second provides an anchor sequence to reconstruct nearby orbits without
recomputing the full authoritative \texttt{mpf\_t} recurrence.

\subsection{Reuse-based orbit regeneration}
\label{subsec:ref-orbit-reuse}

At extreme zoom, a previously computed authoritative orbit may be reused if it remains valid for the
current view. Reuse is gated by two checks:
\begin{enumerate}
  \item \textbf{Precision headroom:} the estimated precision increase demanded by the new view must be below a
        configured extra-precision margin (otherwise, authoritative recomputation is required).
  \item \textbf{Spatial locality:} the parameter delta \(\Delta c = c - c^\star\) must lie within the
        authoritative orbit's validity radius, i.e.\ \(|\Delta x|\le R_{\max}\) and \(|\Delta y|\le R_{\max}\).
\end{enumerate}

\paragraph{Delta-subiteration recurrence.}
Let \(z_n^\star\) be the stored authoritative orbit for \(c^\star\), and let \(z_n\) be the desired orbit for
\(c = c^\star + \Delta c\). Define \(\Delta z_n = z_n - z_n^\star\). For the quadratic map,
\begin{equation}
  z_{n+1}^\star = (z_n^\star)^2 + c^\star,\qquad
  z_{n+1} = (z_n^\star + \Delta z_n)^2 + (c^\star + \Delta c).
\end{equation}
Subtracting gives the exact delta recurrence
\begin{equation}
  \Delta z_{n+1} = 2 z_n^\star\,\Delta z_n + (\Delta z_n)^2 + \Delta c.
\end{equation}

The implementation stores \(\Delta c\) as \((\Delta_0^x,\Delta_0^y)\) and advances
\((\Delta_n^x,\Delta_n^y)\) in \texttt{mpf\_t}, using reuse entries for \(z_n^\star\). Writing
\(z_n^\star = x_n^\star + i y_n^\star\) and \(\Delta z_n = \Delta_n^x + i \Delta_n^y\), the real/imaginary
updates are:
\begin{align}
  \Delta_{n+1}^x &=
    \Delta_n^x\,(2x_n^\star + \Delta_n^x) - \Delta_n^y\,(2y_n^\star + \Delta_n^y) + \Delta_0^x, \\
  \Delta_{n+1}^y &=
    \Delta_n^x\,(2y_n^\star + \Delta_n^y) + \Delta_n^y\,(2x_n^\star + \Delta_n^x) + \Delta_0^y.
\end{align}
Finally, the reconstructed iterate is obtained by
\begin{equation}
  x_n = x_n^\star + \Delta_n^x,\qquad y_n = y_n^\star + \Delta_n^y.
\end{equation}

\paragraph{Reference iteration reset.}
To reduce accumulated error when walking a compressed reuse stream, the code periodically resets the reuse
index back to zero when the delta magnitude becomes comparable to or larger than the current orbit magnitude.
Operationally, it compares low-precision norms
\begin{equation}
  \|\hat{z}_n\|^2 \quad \text{vs.} \quad \|\widehat{\Delta z_n}\|^2,
\end{equation}
and if \(\|\hat{z}_n\|^2 < \|\widehat{\Delta z_n}\|^2\) (or the reuse index reaches the end), it sets
\(\Delta z_n \leftarrow z_n\) and restarts from the beginning of the reuse stream.

\subsection{Multi-threaded CPU acceleration}
\label{subsec:ref-orbit-mt}

The \texttt{MT3} path parallelizes high-cost MPIR operations by splitting the per-iteration work across
threads. Two recurring patterns appear:

\paragraph{Asynchronous squaring.}
For authoritative orbit computation, two worker threads compute \(x_n^2\) and \(y_n^2\) concurrently while the
main thread evaluates the cross term for \(y_{n+1} = 2 x_n y_n + c_y\), performs periodicity checks in low
precision, and orchestrates reuse/serialization. The main update then becomes:
\begin{equation}
  x_{n+1} = x_n^2 - y_n^2 + c_x,
\end{equation}
where \(x_n^2\) and \(y_n^2\) are returned from the worker threads.

\paragraph{Lock-free handoff with prefetch.}
Threads communicate through a minimal \texttt{ThreadPtrs<T>} mailbox containing atomic \texttt{In} and \texttt{Out}
pointers. The protocol is:
\begin{enumerate}
  \item Producer stores a work pointer in \texttt{In}.
  \item Worker spins until it swaps \texttt{In} to \texttt{nullptr}, prefetches the pointed-to operands, executes MPIR
        arithmetic, then publishes the same pointer in \texttt{Out}.
  \item Producer spins until it swaps \texttt{Out} back to \texttt{nullptr}, then consumes the computed fields.
\end{enumerate}
To mitigate cache miss latency on large MPIR limb arrays, the worker explicitly prefetches both MPIR headers
and limb ranges (64-byte stride), which is particularly helpful when iterating at very high precision.

\subsection{GPU reference orbit backend}
\label{subsec:ref-orbit-gpu}

The GPU backend delegates authoritative reference orbit generation to \texttt{HpShark} kernels specialized by
precision. The key design is a persistent \emph{combo} object returned by initialization:
\begin{enumerate}
  \item \texttt{InitHpSharkReferenceKernel}: allocates device/host state for the reference orbit and sets
        \((c_x,c_y)\), max radius, and launch configuration.
  \item \texttt{InvokeHpSharkReferenceKernel}: advances the orbit in bounded batches of at most
        \(\texttt{MaxOutputIters}\), storing results in \texttt{OutputIters}.
  \item \texttt{ShutdownHpSharkReferenceKernel}: frees persistent resources.
\end{enumerate}

Because the precision must be fixed at compile time for the \texttt{HpSharkFloatParams} specialization,
\texttt{DispatchByPrecision} rounds the requested precision to a power of two and chooses from a fixed set
(\(\{256,512,\dots,524288\}\) bits). Each invocation appends the emitted \texttt{OutputIters} records into the
CPU-side \texttt{PerturbationResults}. Periodicity and escape are reported through \texttt{PeriodicityStatus}
and handled similarly to the CPU paths.


\section{Perturbation-only Mandelbrot rendering (without linear approximation)}
\label{sec:perturb-only}

This kernel can render the Mandelbrot set using \emph{perturbation alone}, i.e.,
without taking any LA v2 linear-approximation steps. The same CUDA entry point
\code{mandel\_1xHDR\_float\_perturb\_lav2<IterType,T,SubType,Mode,PExtras>} is
used; the behavior is selected at compile time via \code{LAv2Mode}. In
particular, when \code{Mode} includes only the perturbation path (e.g.\
\code{LAv2Mode::PO}), the kernel skips the LA stage traversal and runs only the
perturbation loop against a stored reference orbit.

\subsection{Rendering objective}
\label{sec:perturb-only-goal}

The goal remains standard escape-time rendering for
\[
z_{n+1} = z_n^2 + c,\qquad z_0=0,
\]
with bailout \(|z|^2 \ge 4\). For each pixel, the kernel computes the parameter
\(c\), iterates until escape or \code{n\_iterations}, and stores the resulting
iteration count in \code{OutputIterMatrix[idx]}.

In perturbation rendering, the expensive high-precision orbit evaluation for
each pixel is avoided by reusing a \emph{reference orbit} computed at a
reference parameter \(c_\star\), then evolving only the \emph{delta orbit} for
nearby pixels.

\subsection{Reference orbit and delta formulation}
\label{sec:perturb-only-deltas}

Let the reference parameter be \(c_\star\), with stored reference orbit
\(\{z_n^\star\}\) satisfying
\[
z_{n+1}^\star = (z_n^\star)^2 + c_\star,\qquad z_0^\star=0.
\]
For a pixel parameter \(c\) near \(c_\star\), define the parameter delta
\[
\Delta c \stackrel{\mathrm{def}}{=} c - c_\star,
\]
and the orbit delta
\[
\Delta z_n \stackrel{\mathrm{def}}{=} z_n - z_n^\star.
\]
Substituting \(z_n = z_n^\star + \Delta z_n\) into the Mandelbrot recurrence
yields the \emph{exact} delta recurrence:
\begin{align}
\Delta z_{n+1}
&= (z_n^\star + \Delta z_n)^2 + (c_\star + \Delta c) - \left((z_n^\star)^2 + c_\star\right) \\
&= 2 z_n^\star\,\Delta z_n + (\Delta z_n)^2 + \Delta c.
\end{align}
Perturbation uses this recurrence directly: it is not a linearization. The work
per iteration is reduced because \(z_n^\star\) is fetched from storage rather
than recomputed in high precision.

\subsection{Pixel parameter delta \texorpdfstring{$\Delta c$}{Delta c}}
\label{sec:perturb-only-deltac}

For each pixel \((X,Y)\), the kernel constructs a delta parameter relative to a
chosen reference center (sign conventions incorporate the image mapping):
\begin{align}
\Delta c_x &= dx \cdot X - \texttt{centerX}, \\
\Delta c_y &= -dy \cdot Y - \texttt{centerY},
\end{align}
and stores this as \code{DeltaSub0} (with scalar components \code{DeltaSub0X},
\code{DeltaSub0Y}). The perturbation state starts at
\[
\Delta z_0 = 0,
\]
so \code{DeltaSubN} is initialized to zero.

\subsection{Perturbation recurrence used in the kernel}
\label{sec:perturb-only-update}

Writing the reference sample as \(z^\star = x^\star + i y^\star\) and the delta
as \(\Delta z = \Delta x + i \Delta y\), the delta recurrence can be expressed
in a factored form convenient for implementation:
\begin{equation}
\Delta z \leftarrow \Delta z \cdot (2 z^\star + \Delta z) + \Delta c.
\label{eq:perturb-factor}
\end{equation}
This identity is equivalent to
\(\Delta z_{n+1} = 2 z_n^\star \Delta z_n + (\Delta z_n)^2 + \Delta c\), because
\(\Delta z\cdot(2z^\star+\Delta z) = 2z^\star\Delta z + (\Delta z)^2\).

The kernel implements \cref{eq:perturb-factor} in real arithmetic by forming
the sums
\[
(2x^\star + \Delta x),\qquad (2y^\star + \Delta y),
\]
then updating:
\begin{align}
\Delta x &\leftarrow \Delta x\,(2x^\star + \Delta x) - \Delta y\,(2y^\star + \Delta y) + \Delta c_x, \\
\Delta y &\leftarrow \Delta x\,(2y^\star + \Delta y) + \Delta y\,(2x^\star + \Delta x) + \Delta c_y.
\end{align}
In the code, the intermediate quantities correspond to:
\begin{verbatim}
tempSum1 = 2*zy + DeltaSubNYOrig;  // (2 y^\star + \Delta y)
tempSum2 = 2*zx + DeltaSubNXOrig;  // (2 x^\star + \Delta x)
\end{verbatim}
followed by the real/imag updates. For extended or HDR types, the kernel routes
the same math through type-specialized implementations
(\code{T::custom\_perturb2} / \code{T::custom\_perturb3}) to keep the inner loop
tight and to enforce the type's reduction/normalization rules.

\subsection{Reconstructing the absolute orbit for escape testing}
\label{sec:perturb-only-reconstruct}

Perturbation evolves \(\Delta z_n\), but escape-time rendering requires a
bailout test on the absolute orbit \(z_n\). Each iteration reconstructs:
\[
z_n \approx z_n^\star + \Delta z_n,
\]
using the stored reference sample \(z_n^\star\) and the current delta. In the
kernel, this appears as:
\[
x = x^\star + \Delta x,\qquad y = y^\star + \Delta y.
\]
The bailout test is then performed on
\[
|z|^2 = x^2 + y^2,
\]
with the canonical threshold \(4\). For HDR and related types, the norm and the
comparison are performed on reduced values using specialized reduced
comparators to keep the escape decision stable at deep zoom.

\subsection{Reference index management and recentering}
\label{sec:perturb-only-recenter}

The perturbation loop advances a reference-orbit index \code{RefIteration} in
lockstep with \code{iter}, fetching \(z^\star\) samples from \code{Perturb}. The
kernel includes a \emph{recentering} mechanism that resets the delta
representation when it becomes ill-conditioned. Conceptually, if the delta
becomes comparable to or larger than the reconstructed orbit, the decomposition
\(z = z^\star + \Delta z\) stops being numerically advantageous. In that case,
the kernel folds the delta into the base by setting:
\[
\Delta z \leftarrow z,\qquad \text{and restart the reference index.}
\]
Operationally, the code compares the reconstructed orbit magnitude proxy
against the delta magnitude proxy, and also recenters if the reference index
reaches the end of the stored orbit samples (to avoid out-of-range sampling).
After recentering, perturbation continues from the new base representation.

This mechanism keeps the perturbation method usable across a wide range of
pixels and iteration depths while preserving the core rendering objective:
compute escape-time using a stable bailout on the reconstructed orbit.

\subsection{Using \code{LAv2Mode} to select perturbation-only execution}
\label{sec:perturb-only-mode}

The kernel is structured as two compile-time phases:
\begin{itemize}
\item an LA v2 phase guarded by \code{Mode == Full || Mode == LAO},
\item a perturbation phase guarded by \code{Mode == Full || Mode == PO}.
\end{itemize}
Therefore, perturbation-only rendering is achieved by instantiating the kernel
with a mode that includes only the perturbation path (e.g.\ \code{LAv2Mode::PO}).
In this configuration:
\begin{itemize}
\item \code{DeltaSub0} is computed from the pixel location,
\item \code{DeltaSubN} remains initialized to \(\Delta z_0 = 0\),
\item the kernel runs the perturbation loop, reconstructing \(z\) each step for
      bailout tests,
\item the final escape-time count is written to \code{OutputIterMatrix}.
\end{itemize}
This provides a complete Mandelbrot renderer based purely on reference-orbit
perturbation, without relying on any linear-approximation hierarchy.

\section{Approximation-based acceleration for Mandelbrot rendering}
\label{sec:approx-accel}

At deep zoom, the cost of iterating high-precision types for every pixel can be
dominant. The remaining components described below are still in service of the
same rendering goal: compute escape-time for \(z_{n+1}=z_n^2+c\), but by reusing
a \emph{reference orbit} and evolving \emph{deltas} for nearby pixels.

\subsection{Bilinear approximation (BLA) for orbit deltas}
\label{sec:bilinear-approx}

\subsubsection{Reference orbit and delta formulation}
Let the reference parameter be \(c_\star\) with orbit:
\[
z_{n+1}^\star = (z_n^\star)^2 + c_\star,\qquad z_0^\star=0.
\]
For a nearby pixel parameter \(c = c_\star + \Delta c\), define:
\[
\Delta z_n \stackrel{\mathrm{def}}{=} z_n - z_n^\star,\qquad
\Delta c \stackrel{\mathrm{def}}{=} c - c_\star.
\]
Expanding the recurrence gives:
\begin{align}
\Delta z_{n+1}
&= (z_n^\star + \Delta z_n)^2 + (c_\star + \Delta c) - \left((z_n^\star)^2 + c_\star\right)\\
&= 2 z_n^\star\,\Delta z_n + (\Delta z_n)^2 + \Delta c.
\end{align}
When \(\Delta z_n\) remains small, the quadratic term can be neglected,
yielding a linearized update:
\begin{equation}
\Delta z_{n+1} \approx A_n\,\Delta z_n + B_n\,\Delta c,\qquad
A_n = 2z_n^\star,\quad B_n = 1.
\end{equation}
BLA generalizes this into precomputed multi-step maps that \emph{jump} multiple
iterations while maintaining an explicit validity bound.

\subsubsection{What \code{BLA<T>} stores}
A \code{BLA<T>} instance stores two complex coefficients:
\[
A = A_x + iA_y,\qquad B = B_x + iB_y,
\]
plus:
\begin{itemize}
  \item \code{r2}: a squared-radius validity bound used during lookup,
  \item \code{l}: the number of Mandelbrot iterations summarized by this step.
\end{itemize}
These objects exist to accelerate \emph{escape-time evaluation} by evolving
\(\Delta z\) cheaply for many pixels, then reconstructing \(z \approx z^\star +
\Delta z\) to perform bailout checks consistent with Mandelbrot rendering.

\subsubsection{Applying a step: complex multiply-add}
The method \code{getValue(RealDeltaSubN, ImagDeltaSubN, RealDeltaSub0, ImagDeltaSub0)}
applies:
\[
\Delta z \leftarrow A\,\Delta z + B\,\Delta c,
\]
expanded into real arithmetic:
\begin{align}
\Re(\Delta z') &= A_x \Re(\Delta z) - A_y \Im(\Delta z) + B_x \Re(\Delta c) - B_y \Im(\Delta c), \\
\Im(\Delta z') &= A_x \Im(\Delta z) + A_y \Re(\Delta z) + B_x \Im(\Delta c) + B_y \Re(\Delta c).
\end{align}

\subsubsection{Composing steps to build longer jumps}
If one step maps \(\Delta z \mapsto A_x\Delta z + B_x\Delta c\) and a second maps
\(\Delta z' \mapsto A_y\Delta z' + B_y\Delta c\), the composition is:
\[
A_{\text{new}} = A_yA_x,\qquad B_{\text{new}} = A_yB_x + B_y.
\]
This supports a hierarchy of step sizes (often powers of two) for quickly
advancing delta orbits while rendering the escape-time field.

\subsubsection{GPU lookup: selecting a valid aligned step}
A GPU-side helper such as \code{GPU\_BLAS} stores the hierarchy and selects a
step that is both \emph{aligned} with the current iteration index and
\emph{valid} under the current bound check (typically comparing a computed
squared-magnitude proxy \code{z2} against \code{r2}). When a step is valid, the
renderer can advance the orbit by \code{l} iterations at a cost far below
performing \code{l} full high-precision Mandelbrot updates.

\subsection{LA v2 linear approximation with perturbation (HDR kernel)}
\label{sec:la-v2-perturb}

This kernel family combines staged linear-approximation steps with a
perturbation finisher loop against a stored reference orbit. The rendering
objective remains escape-time Mandelbrot evaluation; the kernel accelerates
that evaluation by evolving deltas and periodically reconstructing \(z\) to
perform bailout checks.

\subsubsection{Parameter delta per pixel}
Each pixel constructs a parameter offset \(\Delta c\) relative to a selected
reference center (sign conventions may incorporate the image \(Y\)-flip):
\begin{align}
\Delta c_x &= dx\cdot X - \texttt{centerX}, \\
\Delta c_y &= -dy\cdot Y - \texttt{centerY},
\end{align}
and packs \(\Delta c=\Delta c_x+i\Delta c_y\) into \code{DeltaSub0}.

\subsubsection{Delta state and reconstruction}
The kernel maintains \(\Delta z_n\) in \code{DeltaSubN} and reconstructs an
absolute orbit estimate using the stored reference orbit sample
\(z_j^\star\):
\[
z \approx z_j^\star + \Delta z.
\]
Escape-time rendering then proceeds by applying approximation steps when valid,
or performing perturbation updates otherwise, while periodically testing the
bailout condition on the reconstructed \(z\).

\subsubsection{Perturbation update}
Given a reference sample \(z^\star=x^\star+iy^\star\) and \(\Delta z=\Delta
x+i\Delta y\), the perturbation form is:
\[
\Delta z \leftarrow \Delta z\cdot(2z^\star+\Delta z) + \Delta c.
\]
In real arithmetic, with temporaries corresponding to \((2x^\star+\Delta x)\)
and \((2y^\star+\Delta y)\), this yields:
\begin{align}
\Delta x &\leftarrow \Delta x\,(2x^\star+\Delta x) - \Delta y\,(2y^\star+\Delta y) + \Delta c_x, \\
\Delta y &\leftarrow \Delta x\,(2y^\star+\Delta y) + \Delta y\,(2x^\star+\Delta x) + \Delta c_y.
\end{align}
In code comments, write these as \(x^\star\) and \(\Delta x\) (and similarly for
\(y\)) rather than using Unicode symbols.

\subsubsection{Escape test}
After updating \(\Delta z\), reconstruct \(z\approx z^\star+\Delta z\) and test:
\[
|z|^2 = x^2+y^2 \ge 4 \quad\Rightarrow\quad \text{escaped.}
\]
For HDR/expanded types, norms and comparisons are performed using reduced values
and specialized reduced comparators, preserving meaningful bailout decisions at
deep zoom.

\section{Summary: rendering-oriented view}
\label{sec:summary}

All kernels and acceleration schemes described here serve the same rendering
task: compute per-pixel escape-time for the Mandelbrot recurrence
\(z_{n+1}=z_n^2+c\). The implementation provides a precision ladder:
\begin{itemize}
  \item \code{1x} float/double: direct iteration for speed and moderate zoom,
  \item \code{2x} and \code{4x} expansions: deeper zoom with controlled error,
  \item HDR-normalized expansions: stable deep zoom with explicit reduction,
  \item BLA / LA v2 + perturbation: reuse a reference orbit to accelerate
        high-precision escape-time rendering for nearby pixels.
\end{itemize}
The common structure (pixel mapping, orbit iteration, bailout test, iteration
count store) ensures each section remains directly tied to Mandelbrot rendering
as the end goal.

\end{document}
